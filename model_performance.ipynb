{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c701ab-bff1-4146-aa66-bad43598d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def metric_table(table_name=\"training_output.txt\"):\n",
    "    Model_Type=[]\n",
    "    EPOCH=[]\n",
    "    LOSS=[]\n",
    "    True_Prediction=[]\n",
    "    False_Prediction=[]\n",
    "    Accuracy=[]\n",
    "    Precision=[]\n",
    "    Recall=[]\n",
    "    F1_Score=[]\n",
    "    AUC=[]\n",
    "    PR_AUC=[]\n",
    "\n",
    "    with open(table_name,'r') as f:\n",
    "        for line in f:\n",
    "            Model_Type.append(str(line.split(\",\")[0]))\n",
    "            EPOCH.append(int(line.split(\",\")[1]))\n",
    "            LOSS.append(float(line.split(\",\")[2]))\n",
    "            True_Prediction.append(int(line.split(\",\")[3]))\n",
    "            False_Prediction.append(int(line.split(\",\")[4]))\n",
    "            Accuracy.append(float(line.split(\",\")[5]))\n",
    "            Precision.append(float(line.split(\",\")[6]))\n",
    "            Recall.append(float(line.split(\",\")[7]))\n",
    "            F1_Score.append(float(line.split(\",\")[8]))\n",
    "            AUC.append(float(line.split(\",\")[9]))\n",
    "            PR_AUC.append(float(line.split(\",\")[10]))\n",
    "\n",
    "    metrics=pd.DataFrame({\"model_type\":Model_Type,\"epoch\":EPOCH,\"loss\":LOSS,\"true_prediction\":True_Prediction,\"false_prediction\":False_Prediction,\"accuracy\":Accuracy,\\\n",
    "                         \"precision\":Precision,\"recall\":Recall,\"f1_score\":F1_Score,\"auc\":AUC,\"pr_auc\":PR_AUC})\n",
    "    metrics.drop_duplicates(subset=[\"model_type\",\"epoch\"],inplace=True)\n",
    "    metrics.sort_values(by=['model_type','epoch'],inplace=True)       \n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def style_format(metrics, model, type=\"training set\"):\n",
    "    metrics=metrics[metrics[\"model_type\"].apply(lambda x : x.split(\"-\")[0]==model)].reset_index(drop=True)\n",
    "    return metrics.style.format({\"loss\":\"{:.4f}\",\"accuracy\":\"{:.2%}\",\"true_prediction\":\"{:,}\",\"false_prediction\":\"{:,}\", \"precision\":\"{:.2%}\", \"recall\":\"{:.2%}\", \\\n",
    "                                \"f1_score\":\"{:.2%}\", \"auc\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"}) \\\n",
    "    .set_caption(f\"Performance Summary For {type} -- {model}\") \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [\n",
    "            ('color', 'red'),\n",
    "            ('font-size', '20px')\n",
    "        ]\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f1f10-f5e0-42b0-b27c-137c0fcc2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_test=metric_table(table_name=os.path.join(os.getcwd(),\"longformer_base\",\"metrics_training.txt\"))\n",
    "style_format(metric_test, model=\"longformer\", type=\"training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b633f-626f-431b-95a4-5a6f485010fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_test=metric_table(table_name=os.path.join(os.getcwd(),\"roberta_large\",\"metrics_test.txt\"))\n",
    "style_format(metric_test, model=\"roberta\", type=\"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e33421-0eae-4d72-8577-c95fc4a0cbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p38",
   "language": "python",
   "name": "conda_mxnet_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
