{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ae51b-2711-4852-8cf1-e549fcade825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning\")\n",
    "sys.path=list(set(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82081b-e9f3-4427-b2de-817b429fa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment=None\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import utils\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd44d7-dd88-4790-bc94-d87397d5f2f6",
   "metadata": {},
   "source": [
    "#### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fbe4d-40d9-4d83-bb14-9d52763b12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "model_summary=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings-2],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "\n",
    "model_name=\"deberta-v3-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "# model_name=\"deberta-v2-xlarge\"\n",
    "# model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "# config=AutoConfig.from_pretrained(model_path)\n",
    "# tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "# model=AutoModel.from_pretrained(model_path)\n",
    "# num_hidden_layers=config.num_hidden_layers\n",
    "# num_param=sum([p.nelement() for p in model.parameters()])\n",
    "# tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "#                             \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "# model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer-base-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer-large-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"bigbird-roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57391b3-3c9f-4cdd-9b88-3f6dd5200660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta-v3-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "model_summary=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "\n",
    "\n",
    "model_name=\"bigbird-roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33200d68-4004-4393-8180-1f2398326aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_read(df, model_name):\n",
    "    # df=pd.read_csv(os.path.join(output_dir , file_name))\n",
    "    true_y=df[\"True_label\"].values\n",
    "    pred_y=df[\"Predicted_label\"].values\n",
    "    pred_prob=df[\"Predicted_prob\"].values\n",
    "    best_threshold=df['best_threshold'].unique()[0]\n",
    "\n",
    "    # test_output=utils.model_evaluate(true_y.reshape(-1),pred_y)\n",
    "    test_output=utils.model_evaluate(true_y.reshape(-1),pred_prob,best_threshold)\n",
    "    metric=pd.DataFrame()\n",
    "    metric[\"model_type\"]=[f\"{model_name}\"]\n",
    "    metric[\"total complaint #\"]=[test_output[\"total positive\"]]\n",
    "    metric[\"false_positive\"]=[test_output[\"false positive\"]]\n",
    "    metric[\"false_negative\"]=[test_output[\"false_negative\"]]\n",
    "    metric[\"precision\"]=[test_output[\"precision\"]]\n",
    "    metric[\"recall\"]=[test_output[\"recall\"]]\n",
    "    metric[\"f1_score\"]=[test_output[\"f1_score\"]]\n",
    "    metric[\"roc_auc\"]=[test_output[\"AUC\"]]\n",
    "    metric[\"pr_auc\"]=[test_output[\"pr_auc\"]]\n",
    "    return metric\n",
    "\n",
    "def style_format(metrics, type=\"test set\"):\n",
    "    # metrics=metrics[metrics[\"model_type\"].apply(lambda x : x.split(\"-\")[0]==model.split(\"-\")[0])].reset_index(drop=True)\n",
    "    return metrics.style.format({\"total complaint #\":\"{:,}\",\"false_positive\":\"{:,}\",\"false_negative\":\"{:,}\", \"precision\":\"{:.2%}\", \"recall\":\"{:.2%}\", \\\n",
    "                                \"f1_score\":\"{:.2%}\", \"roc_auc\":\"{:.2%}\", \"pr_auc\":\"{:.2%}\"}) \\\n",
    "    .set_caption(f\"Performance Summary for {type} \") \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [\n",
    "            ('color', 'red'),\n",
    "            ('font-size', '15px')\n",
    "        ]\n",
    "    }])\n",
    "\n",
    "def dist_func(df, cols):\n",
    "    tempt1=pd.DataFrame(df[cols].value_counts(dropna=False)).reset_index().rename(columns={'index':cols,cols:'count'})\n",
    "    tempt2=pd.DataFrame(df[cols].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':cols,cols:'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=cols, how=\"inner\")\n",
    "    tempt3=tempt3.loc[:,[cols,'count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format_dist(df,title):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"{title}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '12px')]}])\n",
    "\n",
    "def metrics_df_func(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    N=data_name[0].split(\"_\")[1].split(\".\")[0]\n",
    "    metrics.insert(0,\"Recall in Val\",[f\"recall>={N}0%\"])\n",
    "    \n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        tempt=metrics_read(df,model_name)\n",
    "        N=data_name[i].split(\"_\")[1].split(\".\")[0]\n",
    "        tempt.insert(0,\"Recall in Val\",[f\"recall>={N}%\"])\n",
    "        metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def metrics_df(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        metrics=pd.concat([metrics,metrics_read(df,model_name)],axis=0,ignore_index=True)\n",
    "        \n",
    "    metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc14fa8-c7fa-4489-9a2c-969ede03c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_rate_eval(logit,label,topk):\n",
    "    DF=pd.DataFrame(columns=[\"pred_score\",\"actual_label\"])\n",
    "    DF[\"pred_score\"]=logit\n",
    "    DF[\"actual_label\"]=label\n",
    "    DF.sort_values(by=\"pred_score\", ascending=False, inplace=True)\n",
    "    response_rate={}\n",
    "    for p in topk:\n",
    "        N=math.ceil(int(DF.shape[0]*p))\n",
    "        DF2=DF.nlargest(N,\"pred_score\",keep=\"first\")\n",
    "        response_rate[str(int(p*100))+\"%\"]=DF2.actual_label.sum()/DF2.shape[0]\n",
    "    return response_rate\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def bar_plot(data, colors=None, total_width=0.8, single_width=1, legend=True,title=None,subtitle=None,axis_truncation=0.5):\n",
    "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.pyplot.axis\n",
    "        The axis we want to draw our plot on.\n",
    "\n",
    "    data: dictionary\n",
    "        A dictionary containing the data we want to plot. Keys are the names of the\n",
    "        data, the items is a list of the values.\n",
    "\n",
    "        Example:\n",
    "        data = {\n",
    "            \"x\":[1,2,3],\n",
    "            \"y\":[1,2,3],\n",
    "            \"z\":[1,2,3],\n",
    "        }\n",
    "\n",
    "    colors : array-like, optional\n",
    "        A list of colors which are used for the bars. If None, the colors\n",
    "        will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "    total_width : float, optional, default: 0.8\n",
    "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "        by bars and 20% will be spaces between the bars.\n",
    "\n",
    "    single_width: float, optional, default: 1\n",
    "        The relative width of a single bar within a group. 1 means the bars\n",
    "        will touch eachother within a group, values less than 1 will make\n",
    "        these bars thinner.\n",
    "\n",
    "    legend: bool, optional, default: True\n",
    "        If this is set to true, a legend will be added to the axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if colors where provided, otherwhise use the default color cycle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize =(15, 8))\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in enumerate(values.values()):\n",
    "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "    # Draw legend if we need\n",
    "    if legend:\n",
    "        ax.legend(bars, data.keys())\n",
    "    \n",
    "    ax.set_ylabel('Accuracy',fontsize=15)\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y,_: \"{:.0%}\".format(y)))\n",
    "    ind=np.arange(len(data[list(data.keys())[0]]))\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels( ('top 1% score', 'top 2% score', 'top 5% score','top 10% score') )\n",
    "    ax.set_title(f\"Top Predicted Score  \",fontsize=15)\n",
    "    \n",
    "    #     plt.xlim([0, 1])\n",
    "    # plt.ylim([axis_truncation, 1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea133673-10e4-4917-ab6a-e8913a89ffef",
   "metadata": {},
   "source": [
    "### TFIDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e7621-863f-45aa-98d5-54bdea574a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"xgboost\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b845c2-8984-4b9b-ae43-8343b3765fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"lightgbm\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819dc75-62a7-4f9d-8643-a5d6fc490373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"randomforest\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740a3ce-73e5-4d56-83a7-cb51963c7ac1",
   "metadata": {},
   "source": [
    "### Transformer-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d244d22-b1c9-4604-a2f0-4b791808fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta_large\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"roberta_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37ff7c-bf4e-4743-84ff-1e8f684480e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized roberta_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c95cf-2a70-4066-8df4-fc11158c387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"deberta-v3-large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"deberta-v3-large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42462fc7-9bd7-4c5a-a400-c3ec7d3006ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_96.csv\"))\n",
    "false_positive=df[(df.True_label==0) & (df.Predicted_label==1)]\n",
    "false_negative=df[(df.True_label==1) & (df.Predicted_label==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81fde5-aea2-4b3c-a2f4-034a0655a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length_v2\"]=df[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(df, \"text_length_v2\"),title=\"text length in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004b079-622e-4975-95fc-af3adf36123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment=None\n",
    "false_positive[\"text_length\"]=false_positive[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_positive, \"text_length\"),title=\"text length in false positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4286c6d-6e48-4ac9-9f68-7cc7baf466f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative[\"text_length\"]=false_negative[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_negative, \"text_length\"),title=\"text length in false negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e706b3-fd1d-4bfd-916c-0ef453fe6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_96.csv\"))\n",
    "deberta_v3_true, deberta_v3_pred=df[\"True_label\"].tolist(), df[\"Predicted_label\"].tolist()\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(deberta_v3_true, deberta_v3_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(values_format=',')\n",
    "plt.title(\"deberta-v3-large Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb38ed8-ec19-4102-85da-21abfb5c9cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154c53b-d81b-41aa-a3c2-79303c0dbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v2_xlarge\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"deberta-v2-xlarge\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"deberta-v2-xlarge model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d86a63-d7ca-4651-bc32-f2eed58cfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_base_4096\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"longformer_base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700555bf-d9b6-493d-b72c-576c4aead93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_base_4096_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized longformer_base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63a198-e705-4791-a9f3-dba6c91adc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_large_4096\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"longformer_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79543ca0-b6e1-469c-84f2-2e6134196cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_large_4096_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized longformer_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfb3d6-6177-4cd1-ba84-2e66b57a73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f880a-7981-45d3-b25e-ae9fd7e58503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a214dbe-01c4-480c-97f8-cc72672099fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_92.csv\"))\n",
    "false_positive=df[(df.True_label==0) & (df.Predicted_label==1)]\n",
    "false_negative=df[(df.True_label==1) & (df.Predicted_label==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef368bf-aef7-429a-a8d1-f1e3b8b833f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length_v2\"]=df[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(df, \"text_length_v2\"),title=\"text length in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b4681-dd61-4b6a-a6b3-7efe1ed73264",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment=None\n",
    "false_positive[\"text_length\"]=false_positive[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_positive, \"text_length\"),title=\"text length in false positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67307b1d-4481-4a07-b120-6084873507fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_92.csv\"))\n",
    "bigbird_true, bigbird_pred=df[\"True_label\"].tolist(), df[\"Predicted_label\"].tolist()\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(bigbird_true, bigbird_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(values_format=',')\n",
    "plt.title(\"bigbird Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ef818-ef36-45a0-8b5e-af8c096707dc",
   "metadata": {},
   "source": [
    "### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971f201-8ff1-4fb5-822e-693486e9fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"04_23\"\n",
    "\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/xgboost/\"\n",
    "df=metrics_df(output_dir, \"xgboost\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/lightgbm/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/randomforest/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/roberta_large_customized\"\n",
    "df=metrics_df(output_dir, \"roberta-large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/deberta_v3_large\"\n",
    "df=metrics_df(output_dir, \"deberta-v3-large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/deberta_v2_xlarge\"\n",
    "# df=metrics_df(output_dir, \"deberta-v2-xlarge\")\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/longformer_base_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/longformer_large_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/bigbird_roberta_large_customized\"\n",
    "df=metrics_df(output_dir, \"bigbird_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683a55e-75ad-4aba-8157-ff49f56c8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest','roberta-large','deberta-v3-large','longformer-base', 'longformer-large','bigbird_large']\n",
    "\n",
    "markers = ['o', 's', 'D', 'x', '*', '<', 'p', '^']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'brown','lawngreen', 'purple','black']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=04/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "plt.ylim(0.004,0.018)\n",
    "\n",
    "# Add horizontal line for benchmark model\n",
    "benchmark_precision=0.0053\n",
    "plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b93a9-9c7a-4db2-b007-28e6605b8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.95\n",
    "test_date=\"04_23\"\n",
    "\n",
    "model_name=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics=metrics[metrics.recall>threshold]\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "\n",
    "model_name=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"roberta_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"longformer_base\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"longformer_large\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"bigbird\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93441f-c341-4913-9a37-48460baf659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=metrics.drop([\"Recall in Val\"],axis=1)\n",
    "style_format(metrics,  type=\"Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b877b-662f-4355-b555-29250e0c41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68a2c3-5e08-49fe-bc5b-012a2d329a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=metrics.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "metrics_2=metrics.loc[idx]\n",
    "desired_order=[\"randomforest\",\"xgboost\",\"lightgbm\",\"roberta_large\",\"deberta_v3_large\",\"longformer_base\",\"longformer_large\",\"bigbird\"]\n",
    "metrics_2[\"model_type\"]=pd.Categorical(metrics_2[\"model_type\"],categories=desired_order,ordered=True)\n",
    "metrics_2=metrics_2.sort_values(by=\"model_type\")\n",
    "style_format(metrics_2,  type=\"Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025ec53-839c-456f-bb77-af0ca044ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "model=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550119a-3e01-4f91-8651-6b43a02f6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest','roberta-large','deberta-v3-large','longformer-base', 'longformer-large', 'bigbird-large']\n",
    "\n",
    "markers = ['o', 's', 'D', 'x', '*', '<', 'p', '^']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'brown','lawngreen', 'purple','black']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.scatter(recall[i], precision[i], color=colors[i], marker=markers[i],label=models[i], s=100)\n",
    "    plt.annotate(models[i],(recall[i], precision[i]),xytext=(10,-2),textcoords=\"offset points\")\n",
    "    \n",
    "plt.ylim([0.003,0.015])\n",
    "plt.xlim([0.97,1.001])\n",
    "plt.xticks([0.97,0.98,0.99,1])\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=04/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# Set the legend\n",
    "plt.legend(bbox_to_anchor=(1.35,0.4))\n",
    "\n",
    "# # Add precision and recall values as annotations\n",
    "# for i in range(len(models)):\n",
    "#     for j in range(len(precision[i])):\n",
    "#         x = recall[i][j]\n",
    "#         y = precision[i][j]\n",
    "#         text = f'({precision[i][j]*100:.2f}%, {recall[i][j]*100:.2f}%)'\n",
    "#         plt.annotate(text, (x, y), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40bb1b-b474-4c2a-ad04-9f7b84747804",
   "metadata": {},
   "source": [
    "### top predicted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c6e90-a8cf-45e4-8482-8077bacef1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"04_23\"\n",
    "\n",
    "model_name=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "randomforest_true, randomforest_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "xgboost_true, xgboost_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "lightgbm_true, lightgbm_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "roberta_true, roberta_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "deberta_v3_true, deberta_v3_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "# model_name=\"deberta_v2_xlarge\"\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/{model_name}\"\n",
    "# df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "# deberta_v2_true, deberta_v2_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "longformer_base_true, longformer_base_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "longformer_large_true, longformer_large_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "bigbird_true, bigbird_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222eb695-cb26-4b9a-bb73-9d868db219b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=[0.01,0.02,0.05,0.1]\n",
    "\n",
    "response_lightgbm = response_rate_eval(lightgbm_prob,lightgbm_true, topk)\n",
    "response_xgboost = response_rate_eval(xgboost_prob,xgboost_true, topk)\n",
    "response_randomforest = response_rate_eval(randomforest_prob, randomforest_true, topk)\n",
    "\n",
    "response_deberta_v3 = response_rate_eval(deberta_v3_prob, deberta_v3_true, topk)\n",
    "response_roberta = response_rate_eval(roberta_prob, roberta_true, topk)\n",
    "response_longformer_base = response_rate_eval(longformer_base_prob, longformer_base_true, topk)\n",
    "response_longformer_large = response_rate_eval(longformer_large_prob, longformer_large_true, topk)\n",
    "response_bigbird = response_rate_eval(bigbird_prob, bigbird_true, topk)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = {\n",
    "        \"tfidf+lightgbm\": response_lightgbm,\n",
    "        \"tfidf+xgboost\": response_xgboost,\n",
    "        \"tfidf+random-forest\": response_randomforest,\n",
    "        \"roberta_large\": response_roberta,\n",
    "        \"deberta_v3_large\": response_deberta_v3,\n",
    "        \"longformer-base\": response_longformer_base,\n",
    "        \"longformer-large\": response_longformer_large,\n",
    "        \"bigbird-large\": response_bigbird\n",
    "    }\n",
    "\n",
    "    \n",
    "    CL=['r', 'g', 'b', 'c', 'y', 'darkorange', 'lime', 'grey','gold','bisque', 'lightseagreen', 'purple']\n",
    "    bar_plot(data, colors=CL,total_width=.7, single_width=1,title=\"(response rate)\",subtitle=\"Test Set \",axis_truncation=0.50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941ca3a-c10f-490e-aed6-38e50b63bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_mask_creation(dataset,target_variable, validation_split):\n",
    "    \n",
    "    dataset.sort_values(by='time', ascending=False, axis=0, inplace = True)\n",
    "    dataset=dataset.reset_index(drop=True)\n",
    "    \n",
    "    train_idx=[]\n",
    "    val_idx=[]\n",
    "    \n",
    "    LABEL=dataset[target_variable].values.squeeze()\n",
    "    IDX=np.arange(LABEL.shape[0])\n",
    "    target_list=np.unique(LABEL).tolist()\n",
    "        \n",
    "    for i in range(len(target_list)):\n",
    "        \n",
    "        _idx=IDX[LABEL==target_list[i]]\n",
    "        ## split train and valiation by time instead of randomly\n",
    "        # np.random.seed(seed)\n",
    "        # np.random.shuffle(_idx)\n",
    "        \n",
    "        split=int(np.floor(validation_split*_idx.shape[0]))\n",
    "        \n",
    "        val_idx.extend(_idx[ : split])\n",
    "        print(len(_idx[ : split]))\n",
    "        train_idx.extend(_idx[split:])        \n",
    " \n",
    "    all_idx=np.arange(LABEL.shape[0])\n",
    "\n",
    "    val_idx=np.array(val_idx)\n",
    "    train_idx=np.array(train_idx)\n",
    "    \n",
    "    df_train=dataset.loc[train_idx,:]\n",
    "    df_val=dataset.loc[val_idx,:]\n",
    "    df_val[\"data_type\"]=[\"val\"]*val_idx.shape[0]\n",
    "    \n",
    "    return df_train, df_val\n",
    "\n",
    "data_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"v3_new_email\",\"datasets\",\"split_data\")\n",
    "data_name=[x for x in os.listdir(data_path) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(data_path,data))\n",
    "    df=pd.concat([df,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[-1],x.shape[0]))\n",
    "\n",
    "### only keep emails with status=closed\n",
    "df=df[df.state==\"closed\"]\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values(by='time', inplace = True) \n",
    "## train: 09/2022 ~ 01/2023. validation: 02/2023  test: 03/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2,3]) else \"test\"\n",
    "df[\"data_type\"]=df.progress_apply(set_categories,axis=1)\n",
    "df.loc[:,'target']=df.loc[:,'is_complaint'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "df.loc[:,'is_feedback']=df.loc[:,'is_feedback'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "\n",
    "df1=df[df.data_type==\"train\"]\n",
    "df1=df1.reset_index(drop=True)\n",
    "df_train,df_val=val_mask_creation(df1,'is_complaint', validation_split=0.2)\n",
    "\n",
    "df_test=df[df.data_type==\"test\"]\n",
    "df=pd.concat([df_train,df_val,df_test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cce74-3a21-45a7-b18f-46f9bd4127e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5b2ff-9ad8-4565-a755-b327514d4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"test\")])\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345fcfc-a0cc-4920-9c1f-2b550638e737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
