{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c7f73-1886-4bf0-9ed5-1859832eba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a9dbf-1559-4592-b849-12e30fc6573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(file_name):\n",
    "    with open(file_name,\"r\") as file:\n",
    "        epochs=[]\n",
    "        train_perplexity=[]\n",
    "        val_perplexity=[]\n",
    "        for line in file:\n",
    "            x,y,z=line.strip().split(',')\n",
    "            epochs.append(int(x))\n",
    "            train_perplexity.append(float(y))\n",
    "            val_perplexity.append(float(z))\n",
    "    return epochs, train_perplexity, val_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744aaf6b-5b42-462f-a8bf-c4c1e98f7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer-base\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, longformer_base_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8bc83-c6c6-4167-9e36-8a337141ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, longformer_large_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cab5f-bc5f-4aae-a10f-2acb5a3439e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-base\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, roberta_base_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306e17b-7a44-40f2-81fc-735b16a5128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, roberta_large_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cd459-eafd-4c83-9813-949d745fdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird-roberta-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, bigbird_roberta_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d1305-6acb-4871-bb3f-faf79b3bf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot each model's performance over time as a line chart\n",
    "plt.plot(epochs[:len(roberta_base_perplexity)], roberta_base_perplexity, label='roberta-base', color='purple', linewidth=2, linestyle='-', marker=\"D\")\n",
    "plt.plot(epochs[:len(roberta_large_perplexity)], roberta_large_perplexity, label='roberta-large', color='blue', linewidth=2, linestyle='--', marker=\"o\")\n",
    "plt.plot(epochs[:len(longformer_base_perplexity)], longformer_base_perplexity, label='longformer-base', color='red', linewidth=2, linestyle=':', marker=\"s\")\n",
    "plt.plot(epochs[:len(longformer_large_perplexity)], longformer_large_perplexity, label='longformer-large', color='green', linewidth=2, linestyle='-.', marker=\"^\")\n",
    "# plt.plot(epochs[:len(bigbird_roberta_perplexity)], bigbird_roberta_perplexity, label='BigBird', color='orange', linewidth=2, linestyle='-.', marker=\">\")\n",
    "\n",
    "# Set chart title and axis labels\n",
    "plt.title('Perplexity over Epochs',fontsize=18)\n",
    "plt.xlabel('Epoch',fontsize=12)\n",
    "plt.ylabel('Perplexity',fontsize=12)\n",
    "plt.xticks(epochs)\n",
    "# Add a legend to the chart\n",
    "plt.legend()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054d3f6-cc2c-4270-a3f8-e7df8f02bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning\")\n",
    "sys.path=list(set(sys.path))\n",
    "\n",
    "# path_to_remove=[\"/opt/omniai/work/instance1/jupyter/v2_new_email/\",\"/opt/omniai/work/instance1/jupyter/v2_new_email/Fine-Tuning\"]\n",
    "# for path in path_to_remove:\n",
    "#     if path in sys.path:\n",
    "#         sys.path.remove(path)\n",
    "        \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c8cc2-a381-4dc6-a8d6-3f44b0779b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_read(df, model_name):\n",
    "    # df=pd.read_csv(os.path.join(output_dir , file_name))\n",
    "    true_y=df[\"True_label\"].values\n",
    "    pred_y=df[\"Predicted_label\"].values\n",
    "    pred_prob=df[\"Predicted_prob\"].values\n",
    "    best_threshold=df['best_threshold'].unique()[0]\n",
    "\n",
    "    # test_output=utils.model_evaluate(true_y.reshape(-1),pred_y)\n",
    "    test_output=utils.model_evaluate(true_y.reshape(-1),pred_prob,best_threshold)\n",
    "    metric=pd.DataFrame()\n",
    "    metric[\"model_type\"]=[f\"{model_name}\"]\n",
    "    metric[\"total complaint #\"]=[test_output[\"total positive\"]]\n",
    "    metric[\"false_positive\"]=[test_output[\"false positive\"]]\n",
    "    metric[\"false_negative\"]=[test_output[\"false_negative\"]]\n",
    "    metric[\"precision\"]=[test_output[\"precision\"]]\n",
    "    metric[\"recall\"]=[test_output[\"recall\"]]\n",
    "    metric[\"f1_score\"]=[test_output[\"f1_score\"]]\n",
    "    metric[\"roc_auc\"]=[test_output[\"AUC\"]]\n",
    "    metric[\"pr_auc\"]=[test_output[\"pr_auc\"]]\n",
    "    return metric\n",
    "\n",
    "def metrics_df(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        metrics=pd.concat([metrics,metrics_read(df,model_name)],axis=0,ignore_index=True)\n",
    "        \n",
    "    metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da59a78-263b-4c7e-9e3b-b74685c0a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_base_4096/\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_base_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_large_4096\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_large_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/bigbird_roberta_large\"\n",
    "df=metrics_df(output_dir, \"bigbird_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/bigbird_roberta_large_customized\"\n",
    "df=metrics_df(output_dir, \"bigbird_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e19c6b-d014-4061-a20d-0767b92bdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "# models = ['longformer-base','customized longformer-base', 'longformer-large','customized longformer-large', 'bigbird-large','customized bigbird-large']\n",
    "models = ['longformer-base','customized longformer-base', 'longformer-large','customized longformer-large', 'bigbird','customized bigbird']\n",
    "\n",
    "markers = ['o', 's', 'D', 'x', '*',  'p']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple','black']\n",
    "# markers = ['o', 's', 'D', 'x']\n",
    "# colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26de61-ba07-432d-96e7-368a9b41ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_base_4096/\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/longformer_base_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "# models = ['longformer-base','customized longformer-base', 'longformer-large','customized longformer-large', 'bigbird-large','customized bigbird-large']\n",
    "models = ['longformer-base','customized longformer-base']\n",
    "\n",
    "markers = ['o',  'x', ]\n",
    "colors = ['blue', 'red']\n",
    "# markers = ['o', 's', 'D', 'x']\n",
    "# colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve\\nlongformer-base', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# Set the legend\n",
    "# plt.legend()\n",
    "plt.legend(loc=\"best\",fontsize=14)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343586f-0223-4c5e-9ffe-d893c2f67b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077e2c0-3a96-4363-868d-c2aeda9ecdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524f014-cbe4-4ebc-8c4d-221511998563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56e73d-3853-401d-b732-c5ba68610156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9a292-1fa6-49e1-98d1-79ee798594dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
