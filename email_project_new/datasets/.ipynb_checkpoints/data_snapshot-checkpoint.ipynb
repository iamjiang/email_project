{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b6f7d-9dd8-4d51-b264-2a5cdc6fc93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savez_compressed, load\n",
    "import itertools\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset, concatenate_datasets,DatasetDict\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# Load the stopwords from the new directory\n",
    "nltk_data_dir=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"nltk_data\")\n",
    "stopwords_file = open(nltk_data_dir + '/corpora/stopwords/english')\n",
    "stopwords_list = stopwords_file.readlines()\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "import spacy\n",
    "model_name=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"en_core_web_md\",\"en_core_web_md-3.3.0\")\n",
    "nlp = spacy.load(model_name)\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sns.set(style=\"whitegrid\",palette='muted',font_scale=1.2)\n",
    "rcParams['figure.figsize']=16,10\n",
    "\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None,'display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48fce5-447b-4306-a07b-48b28c34f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v2_new_email/datasets/raw_data\"\n",
    "data_name=[x for x in os.listdir(root_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "df=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_csv(os.path.join(root_dir,data))\n",
    "    x=x.dropna(subset=['email'])\n",
    "    x=x[x.email.notna()]\n",
    "    x=x[x.email.str.len()>0]\n",
    "    df=pd.concat([df,x],axis=0,ignore_index=True)\n",
    "    print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab947a8b-dbf3-421b-a4df-b17a891fd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['year'] = df.time.apply(lambda x: x.year)\n",
    "df['month'] = df.time.apply(lambda x: x.month)\n",
    "df['day'] = df.time.apply(lambda x: x.day)\n",
    "df.sort_values(by='time', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c016b83-5592-4895-aef7-7fd6908abb5a",
   "metadata": {},
   "source": [
    "### remove duplicated emails based on thread id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed202d-11a9-42f7-a214-c258f92e84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df=df.groupby('thread_id')\n",
    "sorted_groups=[group.sort_values(\"time\",ascending=False).reset_index(drop=True) for _, group in grouped_df]\n",
    "df=pd.concat(sorted_groups).drop_duplicates(subset=\"thread_id\", keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac4d20-f04e-4fb3-9ddc-56503d4721cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,year,month):\n",
    "    df=df[(df.year==year) & (df.month==month)]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['year']=year\n",
    "    tempt3['month']=month\n",
    "    tempt3=tempt3.loc[:,['year','month','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df,  data_type=\"Training set\"):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\\n{data_type}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce265ca-8cb2-4d57-8524-5e5f2abf52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,4)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fde20-cf56-44b0-91bd-b145c342b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt1=df['state'].value_counts(dropna=False).reset_index(name=\"count\")\n",
    "tempt2=df['state'].value_counts(dropna=False,normalize=True).reset_index(name=\"percentage\")\n",
    "tempt3=tempt1.merge(tempt2, on=['index'], how=\"inner\")\n",
    "tempt3.rename(columns={\"index\":\"state\"}, inplace=True)\n",
    "tempt3.style.format({'count':'{:,}','percentage':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51941a48-3429-49a4-8139-bd09e69f94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.state==\"closed\"]\n",
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,4)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90068f25-29a9-4933-89a5-c11c2a53ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train: 09/2022 ~ 02/2023. validation: 03/2023  test: 04/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2]) \\\n",
    "else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==3) else \"test\")\n",
    "\n",
    "df[\"data_type\"]=df.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5199b-2d89-49e9-bf35-fc0c83c0471d",
   "metadata": {},
   "source": [
    "### After Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179a7eb-b30e-405f-ade5-ddd15f725f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v2_new_email/datasets/split_data\"\n",
    "data_name=[x for x in os.listdir(root_dir) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df1=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(root_dir,data))\n",
    "    x=x.dropna(subset=['email'])\n",
    "    x=x[x.email.notna()]\n",
    "    x=x[x.email.str.len()>0]\n",
    "    df1=pd.concat([df1,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "df1=df1.reset_index(drop=True)\n",
    "\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df1['year'] = df1.time.apply(lambda x: x.year)\n",
    "df1['month'] = df1.time.apply(lambda x: x.month)\n",
    "df1['day'] = df1.time.apply(lambda x: x.day)\n",
    "df1.sort_values(by='time', inplace = True) \n",
    "\n",
    "grouped_df=df1.groupby('thread_id')\n",
    "sorted_groups=[group.sort_values(\"time\",ascending=False).reset_index(drop=True) for _, group in grouped_df]\n",
    "df1=pd.concat(sorted_groups).drop_duplicates(subset=\"thread_id\", keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3dc5c1-a9d5-471a-81eb-30ace4205624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df1,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,4)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5e2dd-498f-4c4a-907c-df4417effeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt1=df1['state'].value_counts(dropna=False).reset_index(name=\"count\")\n",
    "tempt2=df1['state'].value_counts(dropna=False,normalize=True).reset_index(name=\"percentage\")\n",
    "tempt3=tempt1.merge(tempt2, on=['index'], how=\"inner\")\n",
    "tempt3.rename(columns={\"index\":\"state\"}, inplace=True)\n",
    "tempt3.style.format({'count':'{:,}','percentage':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cc512-b6ab-4f70-b47f-79ee53969790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[df1.state==\"closed\"]\n",
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df1,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,4)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986636c-0689-4e64-be3b-70b8800b4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_month=pd.DataFrame({\"data_type\":[\"train\",\"val\",\"test\"],\\\n",
    "                                   \"month\":[\"09/22 ~ 03/23\",\"09/22 ~ 03/23\",\"04/23\"],\\\n",
    "                                  \"split\":[\"80%\",\"20%\",\"\"]})\n",
    "train_val_test_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc3ece-03a7-4696-ba96-c65787ca674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train: 09/2022 ~ 02/2023. validation: 03/2023  test: 04/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2]) \\\n",
    "else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==3) else \"test\")\n",
    "\n",
    "df1[\"data_type\"]=df1.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98cfcf-0dcd-4906-a34c-b43c9a8de747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15e4a1-67ba-4011-9318-0bbd554163a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"test\")])\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed39db-675e-48cf-bbd5-219de927a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_distribution(df):\n",
    "    tempt1=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False).reset_index(name=\"count\")\n",
    "    tempt2=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False,normalize=True).reset_index(name=\"percentage\")\n",
    "    tempt3=tempt1.merge(tempt2, on=['is_feedback',\"is_complaint\"], how=\"inner\")\n",
    "    tempt3=tempt3.loc[:,['is_feedback','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"feedback distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])\n",
    "\n",
    "dist_df=feedback_distribution(df1)\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305609da-2389-442e-b1b2-9c076690e56f",
   "metadata": {},
   "source": [
    "### email text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994e74c-a60c-4976-a630-274fb76312f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset, concatenate_datasets,DatasetDict\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name=\"longformer-base-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "print()\n",
    "print(f\"Vocabulary size : {tokenizer.vocab_size:,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a39ef3-4154-4bf0-93ce-42566090de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_hf(df):\n",
    "   \n",
    "    train_df=df[df[\"data_type\"]==\"train\"]\n",
    "    val_df=df[df[\"data_type\"]==\"val\"]\n",
    "    test_df=df[df[\"data_type\"]==\"test\"]\n",
    "    \n",
    "    hf_train=Dataset.from_pandas(train_df)\n",
    "    hf_val=Dataset.from_pandas(val_df)\n",
    "    hf_test=Dataset.from_pandas(test_df)\n",
    "    \n",
    "    hf_data=DatasetDict({\"train\":hf_train, \"val\":hf_val,  \"test\":hf_test})\n",
    "    # hf_data=hf_data.select_columns(['snapshot_id','thread_id','time','preprocessed_email','is_feedback','is_complaint'])\n",
    "    \n",
    "    return hf_data\n",
    "\n",
    "hf_v0=dataframe_hf(df)\n",
    "hf_v1=dataframe_hf(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5db6c-a5ee-4791-9ffc-8f62175fa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lenth(example):\n",
    "    return {\"text_length\":len(example[\"input_ids\"])}\n",
    "\n",
    "hf_v0=hf_v0.map(lambda x: tokenizer(x[\"email\"]),batched=True)\n",
    "hf_v0=hf_v0.map(compute_lenth)\n",
    "\n",
    "hf_v1=hf_v1.map(lambda x: tokenizer(x[\"preprocessed_email\"]),batched=True)\n",
    "hf_v1=hf_v1.map(compute_lenth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b7ae0-3cfa-41c7-a74d-a93139e56873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_compute(hf_df1,hf_df2,hf_df3,p=1):\n",
    "\n",
    "    X=[]\n",
    "    X.append(np.percentile(hf_df1['text_length'],p))\n",
    "    X.append(np.percentile(hf_df2['text_length'],p))\n",
    "    X.append(np.percentile(hf_df3['text_length'],p))\n",
    "    \n",
    "    result={}\n",
    "    result['percentile']=X\n",
    "    result[\"min\"]=[np.min(hf_df1['text_length']),np.min(hf_df2['text_length']),np.min(hf_df3['text_length'])]\n",
    "    result[\"max\"]=[np.max(hf_df1['text_length']),np.max(hf_df2['text_length']),np.max(hf_df3['text_length'])]\n",
    "    result[\"mean\"]=[np.mean(hf_df1['text_length']),np.mean(hf_df2['text_length']),np.mean(hf_df3['text_length'])]\n",
    "    return result\n",
    "\n",
    "def statistics_table(hf_df1,hf_df2,hf_df3):\n",
    "    dict_data={}\n",
    "    dict_data[\"data_type\"]=[\"training\", \"validation\", \"test\"]\n",
    "    dict_data[\"# of obs\"]=[len(hf_df1['text_length']),len(hf_df2['text_length']),len(hf_df3['text_length'])]\n",
    "    dict_data[\"Min of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"min\"]\n",
    "    dict_data[\"1% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=1)['percentile']\n",
    "    dict_data[\"5% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=5)['percentile']\n",
    "    dict_data[\"10% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=10)['percentile']\n",
    "    dict_data[\"25% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=25)['percentile']\n",
    "    dict_data[\"Median of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=50)['percentile']\n",
    "    dict_data[\"Average tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"mean\"]\n",
    "    dict_data[\"75% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=75)['percentile']\n",
    "    dict_data[\"90% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=90)['percentile']\n",
    "    dict_data[\"95% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=95)['percentile']\n",
    "    dict_data[\"99% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=99)['percentile']\n",
    "    dict_data[\"Max of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"max\"]\n",
    "    token_count_df=pd.DataFrame(dict_data)\n",
    "    return token_count_df\n",
    "\n",
    "def style_format(token_count_df,  textbody=\"preprocessed_email\"):\n",
    "    token_count_df=token_count_df.set_index(\"data_type\")\n",
    "    token_count_df[list(token_count_df.columns)] = token_count_df[list(token_count_df.columns)].astype(int)\n",
    "    return token_count_df.style.format(\"{:,}\").set_caption(f\"Summary Statistics of token lengths for {textbody} \").set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [\n",
    "            ('color', 'red'),\n",
    "            ('font-size', '15px')\n",
    "        ]\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d812ad4-96fb-4132-9a37-8aad1d1bbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v0[\"train\"],hf_v0[\"val\"],hf_v0[\"test\"])\n",
    "style_format(token_count_df,  textbody=\"email data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c282cb-6ac9-40c7-9ab7-772ddc0a20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"],hf_v1[\"val\"],hf_v1[\"test\"])\n",
    "style_format(token_count_df,  textbody=\"preprocessed email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f424cb-86ea-4563-b112-6f40570b89ea",
   "metadata": {},
   "source": [
    "### text length distribution for complaint email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3dce18-7ed8-4f1f-875f-0152b78a02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"), \\\n",
    "                                hf_v1[\"val\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"),\\\n",
    "                                hf_v1[\"test\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"))\n",
    "style_format(token_count_df,  textbody=\"Complaint email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d37e0-6188-46d9-ae2a-ced121d99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"].filter(lambda x : x[\"is_complaint\"]==\"N\"), \\\n",
    "                                hf_v1[\"val\"].filter(lambda x : x[\"is_complaint\"]==\"N\"),\\\n",
    "                                hf_v1[\"test\"].filter(lambda x : x[\"is_complaint\"]==\"N\"))\n",
    "style_format(token_count_df,  textbody=\"Non-complaint email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfa1de-7cfd-4857-a167-8af6067e6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcut_func(df,var,nbin=5):\n",
    "    df[var]=df[var].astype(float)\n",
    "    df[\"cut\"]=pd.qcut(df[var],nbin,precision=2,duplicates=\"drop\")\n",
    "    decile=df.groupby(df[\"cut\"])['target'].mean().reset_index()\n",
    "    decile[\"cut\"]=decile[\"cut\"].astype(str)\n",
    "    return decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830662a-4105-4613-a05a-10517ba9c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=hf_v1[\"train\"]\n",
    "val_df=hf_v1[\"val\"]\n",
    "test_df=hf_v1[\"test\"]\n",
    "\n",
    "train_df.set_format(\"pandas\")\n",
    "df_train=train_df[:]\n",
    "df_train[\"target\"]=df_train['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)\n",
    "\n",
    "val_df.set_format(\"pandas\")\n",
    "df_val=val_df[:]\n",
    "df_val[\"target\"]=df_val['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)\n",
    "\n",
    "test_df.set_format(\"pandas\")\n",
    "df_test=test_df[:]\n",
    "df_test[\"target\"]=df_test['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064ffc4-c871-47d9-8545-7886b9be001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def y_formatter(x,_):\n",
    "    return f'{x*100:.2f}%'\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,6))\n",
    "plt.subplot(1,3,1)\n",
    "df=pcut_func(df_train,var=\"text_length\",nbin=10)\n",
    "ax[0].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[0].set_title(\"text_length\\n(training set)\")\n",
    "ax[0].set_ylabel(\"complaint %\")\n",
    "ax[0].tick_params(labelrotation=45)\n",
    "ax[0].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "plt.subplot(1,3,2)\n",
    "df=pcut_func(df_val,var=\"text_length\",nbin=10)\n",
    "ax[1].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[1].set_title(\"text_length\\n(validation set)\")\n",
    "ax[1].set_ylabel(\"complaint %\")\n",
    "ax[1].tick_params(labelrotation=45)\n",
    "ax[1].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "plt.subplot(1,3,3)\n",
    "df=pcut_func(df_test,var=\"text_length\",nbin=10)\n",
    "ax[2].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[2].set_title(\"text_length\\n(test set)\")\n",
    "ax[2].set_ylabel(\"complaint %\")\n",
    "ax[2].tick_params(labelrotation=45)\n",
    "ax[2].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f9d8b6-2940-4ebc-bf35-0d3ad4a85caf",
   "metadata": {},
   "source": [
    "#### short and long email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfb1cd-b33f-4a9b-9470-11a2791421e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v2_new_email/datasets/split_data\"\n",
    "data_name=[x for x in os.listdir(root_dir) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df1=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(root_dir,data))\n",
    "    x=x.dropna(subset=['email'])\n",
    "    x=x[x.email.notna()]\n",
    "    x=x[x.email.str.len()>0]\n",
    "    df1=pd.concat([df1,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "df1=df1.reset_index(drop=True)\n",
    "\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df1['year'] = df1.time.apply(lambda x: x.year)\n",
    "df1['month'] = df1.time.apply(lambda x: x.month)\n",
    "df1['day'] = df1.time.apply(lambda x: x.day)\n",
    "df1.sort_values(by='time', inplace = True) \n",
    "\n",
    "### only keep emails with status=closed\n",
    "df1=df1[df1.state==\"closed\"]\n",
    "\n",
    "## train: 09/2022 ~ 02/2023. validation: 03/2023  test: 04/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2]) \\\n",
    "else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==3) else \"test\")\n",
    "df1[\"data_type\"]=df1.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac20f1-6319-4f45-8fed-c6f40cdd2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"long_short\"]=df1['text_length'].progress_apply(lambda x : 1 if x>512 else 0)\n",
    "df_short=df1[df1[\"long_short\"]==0]\n",
    "df_long=df1[df1[\"long_short\"]==1]\n",
    "\n",
    "df_short.drop(\"long_short\", axis=1, inplace=True)\n",
    "df_short=df_short.reset_index(drop=True)\n",
    "\n",
    "df_long.drop(\"long_short\", axis=1, inplace=True)\n",
    "df_long=df_long.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f4afb-ff8d-466a-b498-67f8fe6bd7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df, title):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"{title}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1879da-b954-4dbc-9115-5c5577884742",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"test\")])\n",
    "style_format(dist_df,title=f\"label distribution for short email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6eacc-9855-48e0-92fe-3a0e237d31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"test\")])\n",
    "style_format(dist_df,title=\"label distribution for long email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f10c5-03e0-463e-9dd4-2b00e97aa3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
