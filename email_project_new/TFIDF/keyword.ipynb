{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b13e6-be0f-46d3-a3e6-2d919a95a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment=None\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import re\n",
    "import textwrap\n",
    "import random\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Load the stopwords from the new directory\n",
    "nltk_data_dir=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"nltk_data\")\n",
    "stopwords_file = open(nltk_data_dir + '/corpora/stopwords/english')\n",
    "stopwords_list = stopwords_file.readlines()\n",
    "STOPWORDS=[x.strip() for x in stopwords_list]\n",
    "nltk.data.path.append(nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684b9fc-b19d-4b77-ad04-be0bb9e00185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_preprocess(text):\n",
    "    # lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    text = str(text) \n",
    "    ### Remove stop word\n",
    "    text = [word for word in word_tokenize(text) if word.lower() not in STOPWORDS]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    #Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    text = [w.translate(table) for w in text.split()]\n",
    "    text=\" \".join(text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23099dcf-ae2f-40a6-ab23-52387f0ffa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"v4_new_email\",\"datasets\",\"split_data\")\n",
    "\n",
    "data_name=[x for x in os.listdir(data_path) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(data_path,data))\n",
    "    df=pd.concat([df,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[-1],x.shape[0]))\n",
    "\n",
    "### only keep emails with status=closed\n",
    "df=df[df.state==\"closed\"]\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values(by='time', inplace = True) \n",
    "\n",
    "## train: 09/2022 ~ 02/2023. validation: 03/2023  test: 04/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2,3]) else \"test\"\n",
    "\n",
    "df[\"data_type\"]=df.progress_apply(set_categories,axis=1)\n",
    "\n",
    "df.loc[:,'complaint']=df.loc[:,'is_complaint'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "df.loc[:,'feedback']=df.loc[:,'is_feedback'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "\n",
    "df[\"bag_of_word\"]=df[\"preprocessed_email\"].progress_apply(bow_preprocess)\n",
    "words = set(nltk.corpus.words.words())\n",
    "df[\"bag_of_word\"] = df[\"bag_of_word\"]\\\n",
    ".progress_apply(lambda x: \" \".join(w for w in nltk.wordpunct_tokenize(x) if w.lower() in words ))\n",
    "\n",
    "# df_train=df[df[\"data_type\"]==\"train\"]\n",
    "# df_val=df[df[\"data_type\"]==\"val\"]\n",
    "# df_test=df[df[\"data_type\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09167c11-cb49-45df-a683-699f84b192bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_word=[]\n",
    "with open(\"negative-words.txt\") as f:\n",
    "    for curline in f:\n",
    "        if curline.startswith(\";\"):\n",
    "            continue\n",
    "        if curline.strip():\n",
    "            negative_word.append(curline.strip())\n",
    "            \n",
    "print()\n",
    "print(\"There are {:,} negative words externally\".format(len(negative_word)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef0e7b-9120-4424-a1c3-badf5b4588fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negative_word_set']=df[\"bag_of_word\"].progress_apply(lambda x: set(x.split()).intersection(set(negative_word)))\n",
    "# df_val['negative_word_set']=df_val[\"bag_of_word\"].progress_apply(lambda x: set(x.split()).intersection(set(negative_word)))\n",
    "# df_test['negative_word_set']=df_test[\"bag_of_word\"].progress_apply(lambda x: set(x.split()).intersection(set(negative_word)))\n",
    "\n",
    "\n",
    "df_complaint,  df_no_complaint=df[df['complaint']==1], df[df['complaint']==0]\n",
    "# val_complaint,  val_no_complaint=df_val[df_val['complaint']==1], df_val[df_val['complaint']==0]\n",
    "# test_complaint,  test_no_complaint=df_test[df_test['complaint']==1], df_test[df_test['complaint']==0]\n",
    "\n",
    "df_feedback,  df_no_feedback=df[df['feedback']==1], df[df['feedback']==0]\n",
    "# val_feedback,  val_no_feedback=df_val[df_val['feedback']==1], df_val[df_val['feedback']==0]\n",
    "# test_feedback,  test_no_feedback=df_test[df_test['feedback']==1], df_test[df_test['feedback']==0]\n",
    "\n",
    "def most_common_word(df,feature):\n",
    "    word_count=Counter()\n",
    "    for index,row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if isinstance(row[feature],list):\n",
    "            word_count.update(set(row[feature].split()))\n",
    "        elif isinstance(row[feature],set):\n",
    "            word_count.update(row[feature])\n",
    "    word,freq=zip(*word_count.most_common())\n",
    "    return word,freq\n",
    "\n",
    "word_complaint, freq_complaint = most_common_word(df_complaint, feature=\"negative_word_set\")\n",
    "# word_val_complaint, freq_val_complaint = most_common_word(val_complaint, feature=\"negative_word_set\")\n",
    "# word_test_complaint, freq_test_complaint = most_common_word(test_complaint, feature=\"negative_word_set\")\n",
    "\n",
    "word_no_ccomplaint, freq_no_complaint = most_common_word(df_no_complaint, feature=\"negative_word_set\")\n",
    "# word_val_no_ccomplaint, freq_val_no_complaint = most_common_word(val_no_complaint, feature=\"negative_word_set\")\n",
    "# word_test_no_ccomplaint, freq_test_no_complaint = most_common_word(test_no_complaint, feature=\"negative_word_set\")\n",
    "\n",
    "word_feedback, freq_feedback = most_common_word(df_feedback, feature=\"negative_word_set\")\n",
    "# word_val_feedback, freq_val_feedback = most_common_word(val_feedback, feature=\"negative_word_set\")\n",
    "# word_test_feedback, freq_test_feedback = most_common_word(test_feedback, feature=\"negative_word_set\")\n",
    "\n",
    "word_no_feedback, freq_no_feedback = most_common_word(df_no_feedback, feature=\"negative_word_set\")\n",
    "# word_val_no_feedback, freq_val_no_feedback = most_common_word(val_no_feedback, feature=\"negative_word_set\")\n",
    "# word_test_no_feedback, freq_test_no_feedback = most_common_word(test_no_feedback, feature=\"negative_word_set\")\n",
    "\n",
    "# keyword_training=[w for w in word_train_complaint if w not in word_train_no_churn]\n",
    "# keyword_test=[w for w in word_test_complaint if w not in word_test_no_churn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f1c86-c5d3-4b87-a518-520220aed53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data={}\n",
    "dict_data[\"complaint\"]=word_complaint[0:50]\n",
    "dict_data[\"feedback\"]=word_feedback[0:50]\n",
    "\n",
    "pd.DataFrame(dict_data).style.format().set_caption(\"Most common negative sentiment word in complaint==1 or feedback==1\")\\\n",
    ".set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88992e-3021-4415-b55a-885c5d7c1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=set(word_complaint[0:20]).difference(set(word_no_ccomplaint[0:20]))\n",
    "print()\n",
    "print(word)\n",
    "print()\n",
    "# tempt[\"negative_word\"]=tempt[\"bag_of_word\"].progress_apply(lambda x: 1 if len(set(word).intersection(set(x.split())))!=0 else 0 )\n",
    "df[\"negative_word\"]=df[\"bag_of_word\"].progress_apply(lambda x: 1 if (len(x.split())>0 and any(item in word for item in x.split())) else 0 )\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "ax = sns.barplot(data = df, x='negative_word',y='complaint')\n",
    "ax.set_title(\" Top 50 Negative word in email\", fontsize=16)\n",
    "ax.set_xticklabels([\"no negative word\", \"negative word exist\"])\n",
    "ax.set_ylabel(\"complaint rate\", fontsize=16)\n",
    "ax.set_xlabel(\"\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241ef6f-b76a-4b66-9abc-dd71a625cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=set(word_feedback[0:20]).difference(set(word_no_feedback[0:20]))\n",
    "print()\n",
    "print(word)\n",
    "print()\n",
    "# tempt[\"negative_word\"]=tempt[\"bag_of_word\"].progress_apply(lambda x: 1 if len(set(word).intersection(set(x.split())))!=0 else 0 )\n",
    "df[\"negative_word\"]=df[\"bag_of_word\"].progress_apply(lambda x: 1 if (len(x.split())>0 and any(item in word for item in x.split())) else 0 )\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "ax = sns.barplot(data = df, x='negative_word',y='complaint')\n",
    "ax.set_title(\" Top 50 Negative word in email\", fontsize=16)\n",
    "ax.set_xticklabels([\"no negative word\", \"negative word exist\"])\n",
    "ax.set_ylabel(\"complaint rate\", fontsize=16)\n",
    "ax.set_xlabel(\"\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f75eb-8e98-44ef-9ce0-0f807eadacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df):\n",
    "    tempt1=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False).reset_index(name=\"count\")\n",
    "    tempt2=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False,normalize=True).reset_index(name=\"percentage\")\n",
    "    tempt3=tempt1.merge(tempt2, on=['is_feedback',\"is_complaint\"], how=\"inner\")\n",
    "    tempt3=tempt3.loc[:,['is_feedback','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"is_feedback distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])\n",
    "\n",
    "dist_df=label_distribution(df)\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb05210-9007-4ad0-b689-2e9d3e5672c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96397-fee9-42e1-8141-e7852226005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=set(word_train_complaint[0:50])\n",
    "print()\n",
    "print(word)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64314459-5ec2-40cb-b05e-0e917563fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=set(word_train_complaint[0:50]).difference(set(word_train_no_ccomplaint[0:50]))\n",
    "print()\n",
    "print(word)\n",
    "print()\n",
    "# tempt[\"negative_word\"]=tempt[\"bag_of_word\"].progress_apply(lambda x: 1 if len(set(word).intersection(set(x.split())))!=0 else 0 )\n",
    "df_train[\"negative_word\"]=df_train[\"bag_of_word\"].progress_apply(lambda x: 1 if (len(x.split())>0 and any(item in word for item in x.split())) else 0 )\n",
    "df_val[\"negative_word\"]=df_val[\"bag_of_word\"].progress_apply(lambda x: 1 if (len(x.split())>0 and any(item in word for item in x.split())) else 0 )\n",
    "df_test[\"negative_word\"]=df_test[\"bag_of_word\"].progress_apply(lambda x: 1 if (len(x.split())>0 and any(item in word for item in x.split())) else 0 )\n",
    "\n",
    "df_train[\"negative_word_no_feedback\"]=df_train.progress_apply(lambda x: 1 if (len(x[\"bag_of_word\"].split())>0 and any(item in word for item in x[\"bag_of_word\"].split()) and x['is_feedback']==\"N\") else 0,axis=1)\n",
    "df_val[\"negative_word_no_feedback\"]=df_val.progress_apply(lambda x: 1 if (len(x[\"bag_of_word\"].split())>0 and any(item in word for item in x[\"bag_of_word\"].split()) and x['is_feedback']==\"N\") else 0,axis=1 )\n",
    "df_test[\"negative_word_no_feedback\"]=df_test.progress_apply(lambda x: 1 if (len(x[\"bag_of_word\"].split())>0 and any(item in word for item in x[\"bag_of_word\"].split()) and x['is_feedback']==\"N\") else 0,axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545cd59e-ca03-4d44-8792-63c79637462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt1=df_train.copy()\n",
    "tempt1[\"data_type\"]=[\"training_set\"]*len(tempt1)\n",
    "tempt2=df_val.copy()\n",
    "tempt2[\"data_type\"]=[\"validation_set\"]*len(tempt2)\n",
    "tempt3=df_test.copy()\n",
    "tempt3[\"data_type\"]=[\"test_set\"]*len(tempt3)\n",
    "tempt=pd.concat([tempt1,tempt2,tempt3],axis=0)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "ax = sns.barplot(data = tempt, x='negative_word',y='target',hue=\"data_type\")\n",
    "# ax = sns.barplot(data = tempt, x='negative_word_no_feedback',y='target',hue=\"data_type\")\n",
    "ax.set_title(\" Negative word (top 50) in email\", fontsize=16)\n",
    "ax.set_xticklabels([\"no negative word\", \"negative word exist\"])\n",
    "ax.set_ylabel(\"complaint rate\", fontsize=16)\n",
    "ax.set_xlabel(\"\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e048a-ba94-45dd-bb43-6358168cdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "# ax = sns.barplot(data = tempt, x='negative_word',y='target',hue=\"data_type\")\n",
    "ax = sns.barplot(data = tempt, x='negative_word_no_feedback',y='target',hue=\"data_type\")\n",
    "ax.set_title(\" Negative word (top 50) in email\\n {is_feedback=No}\", fontsize=16)\n",
    "ax.set_xticklabels([\"no negative word\", \"negative word exist\"])\n",
    "ax.set_ylabel(\"complaint rate\", fontsize=16)\n",
    "ax.set_xlabel(\"\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ad3f6-f755-4be0-aaa2-5adca1c600c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_word_dist(df,data_type,col_name=\"negative_word\"):\n",
    "    tempt1=pd.DataFrame(df[col_name].value_counts(dropna=False)).reset_index().rename(columns={'index':col_name,col_name:'count'})\n",
    "    tempt2=pd.DataFrame(df[col_name].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':col_name,col_name:'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=col_name, how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,[\"data_type\",col_name,'count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"negative word in email\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d0c60-b9f9-45cc-9827-45a58a30ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_train,\"train\",\"negative_word\")])\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_val,\"validation\",\"negative_word\")])\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_test,\"test\",\"negative_word\")])\n",
    "dist_df=dist_df[dist_df.negative_word==1].drop([\"negative_word\"],axis=1)\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87597fa2-3a42-41ad-94fe-2c20f799a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_train,\"train\",\"negative_word_no_feedback\")])\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_val,\"validation\",\"negative_word_no_feedback\")])\n",
    "dist_df=pd.concat([dist_df,negative_word_dist(df_test,\"test\",\"negative_word_no_feedback\")])\n",
    "dist_df=dist_df[dist_df.negative_word_no_feedback==1].drop([\"negative_word_no_feedback\"],axis=1)\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"negative word in email\\nis_feedback=No\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc4e56-fce2-4a2a-b2d1-c5d6f5bfcd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddb2ca-5ac1-4fc9-9299-7c7c7d404ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807aa43-584f-4d6e-a789-d9c948e44f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fd9e0-5080-41a7-a62f-99b2d9d60ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
